{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickv779/LADS-Notebooks/blob/main/HW4_Fall25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "socIlC1y00ug"
      },
      "source": [
        "# Homework 4 (The Big One)\n",
        "> With improvements by Gavin Sidhu (Fall 2023)\n",
        "# Lin. Alg. for Data Science.\n",
        "# Due date: hopefully a reasonable one, see discord/canvas\n",
        "\n",
        "# Collaboration rules:\n",
        "> For this task, I'd prefer if you worked on your own. But **if you run into time-consuming technical difficulties** (with Python, numpy, matplotlib) -- feel free to ask for help on discord. Just don't post your code so that you don't spoil anything (especially conceptual).\n",
        "\n",
        "> There are two parts which you can freely discuss on Discord and share code (finding nearest vectors and plotting tiny images).\n",
        "\n",
        "> You can also reuse code from our past notebooks, and check documentation for the libraries, python etc. However, all new code ought to be conceptualized and written by you. In particular, using LLMs to solve any part of the assignment is *not* considered fair game.\n",
        "\n",
        "# Instructions:\n",
        "0. Solve the tasks (by writing Python code).\n",
        "1. Prefix the name of the notebook with your name (e.g. Who_Ever_HW4.ipynb)\n",
        "2. Run all the cells in the notebook, so that all results are visible.\n",
        "\n",
        "3. Important: on colab create a shared link using the option **\"for anyone with the link\"** and switch permission from **Viewer** to **Editor**, so that it says \"Anyone on the internet with the link can edit\".\n",
        "\n",
        "4. Submit the above link on canvas before the deadline. Do not modify the notebook after that.\n",
        "\n",
        "5. The day after the final deadline, **you will be required to answer** some brief questions about your solution via a google form I will send you. This is part of the homework assignment!\n",
        "\n",
        "> This time I will also ask you to copy-paste some of your answers below from this notebook to the form. I know it's annoying, but it'll speed up the grading.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instruction details (READ!)\n",
        "- **You are encouraged to** use the code from our previous notebooks (but do make an effort to understand what is does, don't just copy-paste blindly)\n",
        "\n",
        "- **You MUST NOT** use any language and library elements that were not covered in class colabs. If you feel you absolutely must use something else, contact me.\n",
        "\n",
        "> Rationale: First, while class attendence is not mandatory, I want you to be familiar with class notebooks. Second, this requirement simulates a situation in which you need to get proficient with in-house software tools developed by your company. Also, this should discourage *some* of you from blindly using LLMs, which unfortunately has been happenning. (Most of you don't do this so it's annoying -- but I suppose you don't necessarily want to share your hard-earned A with someone who just chatGPT-ed their way through their education...)\n",
        "\n",
        "- Tasks (**marked T:**) require you to do some coding (usually in the code cell directly below).\n",
        "\n",
        "- Questions (**marked Q:**) require you to briefly answer some questions in text. Make sure the answers highlight your understanding of the: mathematics, algorithms, important insights from data visualizations etc.\n",
        "\n",
        "For clarity, **please answer each question like this** directly below the question (and not as a comment in the code.):\n",
        "\n",
        "> **A**:\n"
      ],
      "metadata": {
        "id": "v_A7VIwL_CU6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Asq2N4v_TRN"
      },
      "source": [
        "# Overview\n",
        "\n",
        "The **objective** of this notebook is to **explore and analyze** a realistic image dataset called cifar100, which contains 60,000 color images.\n",
        "\n",
        "Due to the dataset's size, manually examining each image is impractical. Instead, we will use t-SNE and kMeans and also investigate nearest neighbors using the Euclidean metric.\n",
        "\n",
        "Previously, our focus was mostly on MNIST, which contains real data but is heavily preprocessed and idealized for our use. Now, our goals are to:\n",
        "\n",
        "- Evaluate the performance of t-SNE, kMeans, and kNN when applied to more realistic images\n",
        "- Identify patterns in the images, their tSNE embeddings and k-means clusters and nearest neighbours -- and explain why they occur.\n",
        "- Recognize the limitations of these methods.\n",
        "\n",
        "Our main operations will involve working with high-dimensional vectors, norms, distances, sums, and means.\n",
        "\n",
        "There will be four main parts in this notebook:\n",
        "\n",
        "1. Loading the data and checking its format is correct for our use\n",
        "2. Preparing a function for identifying nearest neighbors\n",
        "3. Conducting exploratory data analysis with t-SNE (with an extra step using nearest neighbor search)\n",
        "4. Performing data analysis by clustering with kMeans (using insights from the previous part)\n",
        "\n",
        "There is also be a bonus section where you can upload your own image and look at similar images! And another one in which you can play with another, newer method instead of tSNE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guidelines\n",
        "- Follow the assigned tasks in a reasonable manner\n",
        "- Note that this is one big assignment focusing on data analysis, not many isolated tasks.\n",
        "- You will likely need to do several iterations on this assignment. It's a good idea to start from a reasonably small subset of the data just to make sure everything works.\n",
        "- Provide brief yet informative answers to the questions. Elaborate when necessary, but be concise.\n",
        "- Make sure your plots, visualizations, and other outputs are clean and informative.\n",
        "\n",
        "- This is a large assignment focusing on data analysis. The point below are important, but not as crucial:\n",
        "    * Writing efficient code (although it might test your patience if it's too slow)\n",
        "    * Ensuring code readability (it will make life easier, though)\n",
        "    * Including comments (but they might help when you have to fill out the form)\n",
        "\n",
        "- Do consider defining functions for repetitive tasks, like finding nearest neighbors\n",
        "\n",
        "- Do make sure you use the appropriate tool for each task -- and that your use it correctly.\n",
        "\n",
        "**Note:** This is a substantial assignment, and while coding details won't be nitpicked at during grading, prioritizing clarity where possible will *probably* enhance your overall experience. Same for efficiency.\n",
        "\n",
        "**Another note:** I use the term plot loosly. It can mean plt.plot, scatter, imshow etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "CwbZxtN1TlEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n",
        "\n",
        "**T:** Import the things you need -- and nothing else!\n",
        "\n",
        "> Hopefully this will make sure that you didn't just copy-paste all the imports from all my previous notebooks."
      ],
      "metadata": {
        "id": "Xb_cozO5G5G0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDJkBD7aW0Qm"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar100 # this will get you the data!\n",
        "\n",
        "# add all other needed imports and not unnecessary ones\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUw0wU2nXSmC"
      },
      "source": [
        "# The data\n",
        "\n",
        "> CIFAR-100 is another classical image dataset. We have experience with using MNIST, and the format will be quite similar. Each image is 32x32, with 3 color values (R,G,B) for each pixel ranging from 0-255."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data (like we did with MNIST)\n",
        "\n",
        "> Recall that mnist.load_data() returned two pairs:\n",
        "(train_images, train_labels), (test_images, test_labels).\n",
        " We will mostly use train_images, and train_labels at one occasion. It works similarly for the CIFAR-100 dataset imported above."
      ],
      "metadata": {
        "id": "-BKu16h8Be4j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAyWiayzeotx"
      },
      "outputs": [],
      "source": [
        "# Use CIFAR-100\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> To avoid problems later, ensure they are float values between 0 and 1.\n",
        " Be sure to not re-run the code for doing this without first re-initializing the data using the above code, otherwise you may accidentally scale the data down even further.\n",
        "\n",
        "> Double check the shape of the arrays you loaded. Also ensure you have normalized the R,G,B values to between 0 and 1."
      ],
      "metadata": {
        "id": "zA15-7w7Ug8y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPsYf4fCBDMJ"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Plot the image with the index defined below. Hint: use plt.imshow and not plt.plot!"
      ],
      "metadata": {
        "id": "4LTguZ-Olo-Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dinlt6fZARtO"
      },
      "outputs": [],
      "source": [
        "ind = 4311\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Channels of an RGB image\n",
        "\n",
        "> An image has 3 channels corresponding to R,G,B.\n",
        "\n",
        "**T:** Plot each channel (of the image you plotted) separately using plt.imshow. Then look at the 3 plots. Which channel (R,G,B) contributes the most (has highest intensity values)?\n",
        "\n",
        "> Hint: You'll likely use a syntax similar to how we selected the columns of a 2D array.\n",
        "\n",
        "**Q:** Is the result consistent with your expectation based on eyeballing the original image?\n",
        "\n",
        "> **Answer**:"
      ],
      "metadata": {
        "id": "twwxcaLBCAgS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFSxIwh__rS8"
      },
      "outputs": [],
      "source": [
        "for i in range(3): # it's okay to use loops when it makes sense\n",
        "  # Your code here -- remove unnecessary comments like this one!\n",
        "  plt.show() # remember to force each image to be plotted!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Closest images"
      ],
      "metadata": {
        "id": "kfOxKUvzHKvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Recall that we can think about an image as a vector in a high-dimensional vector space, $\\mathbb{R}^d$.\n",
        "\n",
        "**T:** Write a **Python function** which returns the $k$ nearest vectors (or in this case, the $k$ nearest images) using the Euclidean distance.\n",
        "\n",
        "> Tip: Try to use np.argsort for efficient sorting -- it's very useful whenever we talk about finding k nearest vectors. It may be convenient to have one function returning the indices, and another returning the actual images (perhaps using the previous function).\n",
        "\n",
        "> If you get stuck here, search the colabs and feel free to ask for help on Discord -- that's okay, it's not the point of this assignment.\n",
        "\n",
        "**T:** Test this function briefly, so that you're sure it works.\n",
        "\n",
        "> Simple unit tests with asserts are enough.\n",
        "\n",
        "**T:** Compute and plot a bunch of images closest to the above image. For clarity, plot the images in a horizontal row.\n",
        "\n",
        "> As a gesture of good faith, below is a helpful function I wrote *especially* for you!\n",
        "\n"
      ],
      "metadata": {
        "id": "DTx0oAhaCRRR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KMswDPmQkar"
      },
      "outputs": [],
      "source": [
        "def plot_images_in_a_row(ims):\n",
        "  'Takes a list/array of images and plots them spaced horizontally.'\n",
        "  _, axs = plt.subplots(1, len(ims), figsize = (20,5))\n",
        "  for im, ax in zip(ims, axs.ravel()):\n",
        "    ax.imshow(im)\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "lG7CNd3kGj8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B237NCUnpdrX"
      },
      "source": [
        "# Exploring the data with t-SNE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**T:** Set up t-SNE with appropriate parameters.\n",
        "\n",
        "> Tip: Use the \"random_state\" parameter in the TSNE function to ensure you get the same results if you have to re-run the notebook!\n",
        "\n",
        "**T:** Make sure there are *no warnings* printed (you may need to set some additional parameters)."
      ],
      "metadata": {
        "id": "MEaxiGbcEQEd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYw9PV0366Rd"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**T:** Fit the model with your data and retreive the result. (Remember that t-SNE doesn't know -- or care -- about 2D images)\n",
        "\n",
        "> Hint: You may need to limit the amount of data, since t-SNE tends to be slow. You could even work with a small subset and increase it to a larger subset for the final result. Try to be smart about it, otherwise you'll wait forever for t-SNE to finish!\n",
        "\n",
        "> Fun fact: Even disregarding the dimension of the space, performing t-SNE on $n$ data points has a time complexity of $\\Omega(n^2)$, so you can see why starting with a small subset may be a good idea!\n",
        "\n",
        "> Overall, you may lose a lot of time if you recompute all the notebook on too large data. You may start small and quick, and rerun on larger data once things work."
      ],
      "metadata": {
        "id": "Ll43PckQt9tg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AOSSBibbYSwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnMuxExDpif5"
      },
      "source": [
        "## Plotting t-SNE embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**T:** Scatter-plot the output of t-SNE.\n",
        "\n",
        "**Q:** Can you see any significant structure? Maybe some groups? If so where are they on the plot.\n",
        "\n"
      ],
      "metadata": {
        "id": "XBHCgt9Fq7Wp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OUQl-wOTJUR"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**T:** Now scatterplot the output, but assigning a color (can be random)\n",
        "depending on the label (remember y_train!). We want any images with the same label to be the same color.\n",
        "\n",
        "**Q:** How well does the structure reflect the labels? Are the labels clustered or not? Mention some example labels, their colors and their coordinates range on the plot."
      ],
      "metadata": {
        "id": "cC_JsHfMsT6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "-T5Dx1ibrD1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0) # to fix the random colors\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "BIPu-2R-fnRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5QOF7bOp03P"
      },
      "source": [
        "## Plotting the images in t-SNE embedding space"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**T:** Plot the t-SNE output again --\n",
        "but now plot the original images at locations given by t-SNE (as we did in class, you can reuse this code!).\n",
        "\n",
        "> If this gives you problems, ask on Discord. Sometimes it can fail in non-obvious ways, no need to waste time on this.\n",
        "\n",
        "**Q:** Can you see significant structures now? Any groups of similar images? What specific images can you see, and at what coordinates? In what sense are they 'similar'?\n",
        "\n",
        "> (Tip: if the generated plot is large, you can click on it and zoom. You can also save the ouput, download the resulting image on your computer\n",
        "And zoom it more comfortably.)"
      ],
      "metadata": {
        "id": "loL2F8b7qx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hint: make sure you scatter-plot the points, or the images may\n",
        "# not show up!\n",
        "\n",
        "np.random.seed(0)\n",
        "plt.figure(figsize = (40,40)) # larger figure may be better\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "Q-vTFPL3fMey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing perplexity values\n",
        "\n",
        "> As mentioned earlier, the perplexity parameter controls roughly how many neighbours of each vector are taken into account when doing the dimensionality reduction.\n",
        "\n",
        "**T:** Fit two new t-SNE models on your data using different perplexity values (perhaps one with a lower perplexity than your original model, and one higher?).\n",
        "\n",
        "**Q:** How did the perplexity parameter affect the structure of the t-SNE output? Mention 3 choices giving vastly different results. Keep the plots.\n",
        "\n",
        "> Try not to copy paste the code, you can do it in a for loop!\n"
      ],
      "metadata": {
        "id": "mEwtzt5KfrrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "ESFQzusunWNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patterns inside groups of images\n",
        "\n",
        "> There should be groups of 'similar' images, according to some visible **pattern**. For example, you can see:\n",
        "\n",
        "> - Images with a centered object on a white background\n",
        "> - Images with the sky in the upper part and distinct objects in the lower part\n",
        "\n",
        "\n",
        "**Q:** Find at least 5 new **patterns**, and describe them briefly but concretely (make sure to include the coordinates at which they appear)!\n",
        "\n",
        "## Important question:\n",
        "\n",
        "**Q**: *Why* do you think t-SNE picks up these patterns? **This is an important question, so be sure to elaborate!** Refer to the patterns you identified. Your answer should highlight your understanding of t-SNE and related concepts."
      ],
      "metadata": {
        "id": "-ipZQMnorR5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> For each of the 5 types of **patterns**\n",
        "you identified, we can select their\n",
        "representative images using their t-SNE coordinates.\n",
        "\n",
        "> Tip: suppose someone would like to perform such a query many, many times. Can you make it efficient for them? Do it in the code.\n",
        "\n",
        "> For example: in my case \"the things on a white background\",\n",
        "had t-SNE coordinates close to $(-15,-15)$, so I found 10 images with t-SNE\n",
        "coordinates closest to $(-15,-15)$. I then plotted them in one row.\n",
        "\n",
        "**T:** Do the above for your five selected types of **patterns**.\n",
        "\n",
        "**Q:** Did you get similar images? Mention similarities and differences you see, be specific.\n"
      ],
      "metadata": {
        "id": "DUMfeVftqiYf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWydQvfc1bEe"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Back to the high-dimensional space!"
      ],
      "metadata": {
        "id": "fVvg-bmRZ_qC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Let's try a similar thing in the original, high-dimensional space.\n",
        "\n",
        "**T:** Pick a representative image for each of the 5 **patterns**, and find 10 images which are closest *in the original high-dimensional space*. Plot them (in horizontal rows).\n",
        "\n",
        "## Important question:\n",
        "\n",
        "**Q**: The results are most likely **not** the same as previously. Do you understand why? **This is really important, elaborate!** Make sure it's clear you know what's happening here."
      ],
      "metadata": {
        "id": "ov3GT3hxqbPz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVIB8fU5186K"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azC-xbPSpUr4"
      },
      "source": [
        "# Clustering with k-Means\n",
        "\n",
        "> We can use the insights obtained from the 'exploratory data analysis' performed in the previous part, to preform our data analysis in a reasonable way. In particular, it should give us a hint about a reasonable number of clusters to use.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q:** Based on the last part, how many clusters do you think is good for kMeans? Why? Be specific.\n",
        "\n",
        "**T:** Set up KMeans with some rasonable $k$ based on the previous part (no worries: there is no single best answer).\n",
        "\n",
        "> Tip: to speed things up, import and use **MiniBatchKMeans** instead of KMeans. Browse the documentation to know how it differs. We did not cover this in class, but you can use it.\n",
        "\n",
        "> In short: MiniBatchKMeans is less accurate, faster, good enough here, and you use it the same way. You don't have to use it -- but not using it will cost you more time and you will lose some credit. So, you know, just use it."
      ],
      "metadata": {
        "id": "YhBJ5_C8olev"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De2Wm1AaX4_h"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**T:** Fit kMeans with your data."
      ],
      "metadata": {
        "id": "BLadx_xPoqhT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_zBPFnMYEgq"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot t-SNE embedding using clusters' labels\n",
        "\n",
        "> Let's see to what extent the kMeans clusters\n",
        "resemble the structure of the t-SNE output.\n",
        "\n",
        "**T:** Plot the t-SNE embedding again -- but this time assign\n",
        "colors corresponding to the kMeans cluster of each image.\n",
        "\n",
        "**Q:** Can you see significant groups of points with the same color (label)? (If not, something is wrong.) How many do you see, roughly? Describe them, mention the rough position (x,y) and some characteristic features for some of them.\n"
      ],
      "metadata": {
        "id": "AmDKf5dFovbr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pZg7IWnbE4o"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**T:** Repeat the plot above but **define the color of each point as the (approximate) mean color of\n",
        "the images in the cluster** to which the image belongs to.\n",
        "\n",
        "> Hint: try to find a simple way of getting these colors.\n",
        "\n",
        "> You should see some blue and orange parts. Also some almost white and quite dark parts? If yes -- good. **When in doubt, it's okay to post this particular image on discord and ask!**\n",
        "\n",
        "> If you don't see them -- something is likely wrong. Maybe too few iterations? If everything is gray, something is very  wrong -- maybe way too few clusters (k). Tune the parameters until happy. Do you see why we wanted to use the faster, approximate version of k-means? Data analysis is often done iteratively/interactively -- so efficient algorithms save your time.\n",
        "\n",
        "**Q**: Describe 5 features you see on the plot, along with their tSNE coordinates."
      ],
      "metadata": {
        "id": "cazg5V7En3s8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "pxIgQm9SpdNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## On the entire dataset"
      ],
      "metadata": {
        "id": "BuCEdDJnIdCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> If you're not satisfied with the quality, you can tune the parameters some more.\n",
        "\n",
        "**T:** If everything looks acceptable, rerun the analysis on the full dataset."
      ],
      "metadata": {
        "id": "AVEeK22qoHCq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft7yUjGa0Tfl"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Let's verify if the clusters we got on the entire dataset are reasonable.\n",
        "\n",
        "**T:** For each cluster center, plot, say, 10 images which are closest in the sense of the Euclidean metric to it. Also plot the cluster center!\n",
        "\n",
        "**Q:** Looks good? Or maybe you see something suspicious? Describe some examples.\n",
        "\n",
        "> For example: if any cluster center look like a single image in the dataset, you likely chose too many clusters!"
      ],
      "metadata": {
        "id": "IRHeqDuAoOak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff64wTTYcfP4"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AF256FnAGlk"
      },
      "source": [
        "# Bonus \\#1 [some extra credit]:\n",
        "\n",
        "Try your own image! Does it belong to a cluster you'd expect? What do you see?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98fh489cHtuo"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "\n",
        "def get_uploaded_image(size = (32,32)):\n",
        "  '''Lets you download and image.\n",
        "  Returns an np.array representing the downloaded image.\n",
        "  The image is resized to the provided size.\n",
        "  '''\n",
        "  filename = list(files.upload())[-1]\n",
        "  im = Image.open(filename).resize(size)\n",
        "  npim = np.array(im)[..., :3].astype(float)\n",
        "  if npim.max() > 2:\n",
        "    npim /= 255.\n",
        "  return npim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your_image = get_uploaded_image() # uncomment and run to download an image\n",
        "#plt.imshow(your_image)"
      ],
      "metadata": {
        "id": "8E01pPrqp5Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**T:** Plot the 'most similar' images to the cluster closest to the image. (Hint: You can do this on your own, but Kmeans has a function called 'predict' which returns the index of the closest cluster center.)\n",
        "\n",
        "**T:** Plot the 'most similar' images to your image.\n",
        "\n",
        "**Q:** Is there any advantage to finding the 'most similar' images via the clusters? What are the benefits? What do we lose? How is this tradeoff affected by the number of clusters? Please elaborate!\n",
        "\n",
        "> (Answer)\n"
      ],
      "metadata": {
        "id": "V-rtEueAoW2u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKOWSiqP-0jE"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus \\#2 [more extra credit]\n",
        "\n"
      ],
      "metadata": {
        "id": "VDUguVxoahfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We have been working with t-SNE to lower the dimensions of our data, but now I want to briefly introduce you to another, newer technique called UMAP (Uniform Manifold Approximation and Projection). While t-SNE emphasizes local relationships, UMAP tries to preserve both local and global structures.\n",
        "\n",
        "**T:** Below is code to import the package for UMAP. Research the documentation and fit UMAP to your same data as before. The syntax should be fairly similar. Then plot the two scatterplots containing the colored labels and the images themselves.\n",
        "\n",
        "**Q:** During your research, you may have come across documentation for UMAP's parameters (if you didn't, go back and look!). Briefly explain the two important parameters (they're both numeric)."
      ],
      "metadata": {
        "id": "Cgwf2Srpfasw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "XDWgczCzboPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap"
      ],
      "metadata": {
        "id": "VCdAEYVXbldw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qTplgF7cb4Xi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}